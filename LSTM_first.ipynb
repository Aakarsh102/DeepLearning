{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"HtZUjifR451S"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch import optim\n","import numpy as np\n","import pandas as pd\n","from torch.utils.data import TensorDataset, DataLoader\n","from pytorch_lightning import LightningDataModule\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12915,"status":"ok","timestamp":1711918268786,"user":{"displayName":"Aakarsh Rai","userId":"06387172182894839107"},"user_tz":240},"id":"dRNN0xJS5upl","outputId":"88c8be6c-e91d-4862-de59-a18a6453e402"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting lightning\n","  Downloading lightning-2.2.1-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.10/dist-packages (from lightning) (6.0.1)\n","Requirement already satisfied: fsspec[http]<2025.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2023.6.0)\n","Collecting lightning-utilities<2.0,>=0.8.0 (from lightning)\n","  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n","Requirement already satisfied: numpy<3.0,>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.25.2)\n","Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (23.2)\n","Requirement already satisfied: torch<4.0,>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2.1.0+cu121)\n","Collecting torchmetrics<3.0,>=0.7.0 (from lightning)\n","  Downloading torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.5/841.5 kB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.66.2)\n","Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.10.0)\n","Collecting pytorch-lightning (from lightning)\n","  Downloading pytorch_lightning-2.2.1-py3-none-any.whl (801 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m801.6/801.6 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning) (2.31.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning) (3.9.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities<2.0,>=0.8.0->lightning) (67.7.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (3.13.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (3.1.3)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (2.1.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<4.0,>=1.13.0->lightning) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<4.0,>=1.13.0->lightning) (1.3.0)\n","Installing collected packages: lightning-utilities, torchmetrics, pytorch-lightning, lightning\n","Successfully installed lightning-2.2.1 lightning-utilities-0.11.2 pytorch-lightning-2.2.1 torchmetrics-1.3.2\n"]}],"source":["%pip install lightning\n","import lightning as l"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W41K2Gdq6MhR"},"outputs":[],"source":["class LightningLSTM(l.LightningModule):\n","    def __init__(self):\n","      super().__init__()\n","      self.lstm = nn.LSTM(input_size = 20,num_layers = 3, hidden_size = 1)\n","\n","    def forward(self, df):\n","      st_mem, varr = self.lstm(df)\n","      prediction = st_mem[-1]\n","      return prediction\n","\n","    def configure_optimizers(self):\n","      optimizer = optim.Adam(self.parameters(), lr=0.01)\n","      return optimizer\n","\n","    def calculate_loss(self, input, output):\n","      loss_function = nn.BCEWithLogitsLoss()\n","      return loss_function(input, output)\n","\n","    def training_step(self, batch, batch_idx):\n","      input_df, label_df = batch\n","      output_lstm = self.forward(input_df)\n","      loss = self.calculate_loss(output_lstm, label_df)\n","      return loss\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"asnqgourXiwd"},"outputs":[],"source":["first_lstm_model = LightningLSTM()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":187},"executionInfo":{"elapsed":822,"status":"ok","timestamp":1711913890908,"user":{"displayName":"Aakarsh Rai","userId":"06387172182894839107"},"user_tz":240},"id":"AHMI-3PN6MlP","outputId":"b8afb4d9-da55-4a99-e22c-d311fb1990e2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<bound method Module.parameters of LightningLSTM(\n","  (lstm): LSTM(20, 1, num_layers=3)\n",")>"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>torch.nn.modules.module.Module.parameters</b><br/>def parameters(recurse: bool=True) -&gt; Iterator[Parameter]</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py</a>Return an iterator over module parameters.\n","\n","This is typically passed to an optimizer.\n","\n","Args:\n","    recurse (bool): if True, then yields parameters of this module\n","        and all submodules. Otherwise, yields only parameters that\n","        are direct members of this module.\n","\n","Yields:\n","    Parameter: module parameter\n","\n","Example::\n","\n","    &gt;&gt;&gt; # xdoctest: +SKIP(&quot;undefined vars&quot;)\n","    &gt;&gt;&gt; for param in model.parameters():\n","    &gt;&gt;&gt;     print(type(param), param.size())\n","    &lt;class &#x27;torch.Tensor&#x27;&gt; (20L,)\n","    &lt;class &#x27;torch.Tensor&#x27;&gt; (20L, 1L, 5L, 5L)</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 2171);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":24}],"source":["first_lstm_model.parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k2qDAjK46MoS"},"outputs":[],"source":["df = pd.read_csv(\"drive/MyDrive/neurotech/eeg_data.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":105,"status":"ok","timestamp":1711918929189,"user":{"displayName":"Aakarsh Rai","userId":"06387172182894839107"},"user_tz":240},"id":"Z2HE853l6Mqr","outputId":"0111290c-ec5e-4f0d-dcc9-cce98bc5000e"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"]}],"source":["trainer = l.Trainer(max_epochs = 10, log_every_n_steps = 5, accelerator = \"gpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lbvWa1OMdsA1"},"outputs":[],"source":["inputs = df.iloc[:, :-1].values\n","labels = df.iloc[:, -1].values\n","\n","inputs_tensor = torch.from_numpy(inputs).float()\n","labels_tensor = torch.from_numpy(labels).float()\n","inputs_tensor.to(\"cuda\")\n","labels_tensor.to(\"cuda\")\n","\n","dataset = TensorDataset(inputs_tensor, labels_tensor)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nt-WqKEwhl1c"},"outputs":[],"source":["dataloader = DataLoader(dataset, shuffle = False, batch_size=375)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":116,"status":"ok","timestamp":1710620288855,"user":{"displayName":"Aakarsh Rai","userId":"06387172182894839107"},"user_tz":420},"id":"cai7bf1xfLaK","outputId":"57f0b8a4-2f88-42a1-ee71-ef78b7056b59"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 1.2518e+04, -7.2849e+02, -1.8749e+04, -4.4856e+03, -7.3973e+02,\n","         -8.3338e+03, -1.4044e+04, -2.2720e+04, -2.5476e+04, -5.9475e+04,\n","         -1.5328e+04, -1.3861e+04, -1.9199e+04, -1.8368e+04, -1.4253e+04,\n","         -2.7908e+04, -1.0400e-01,  9.6800e-01,  2.6000e-01,  1.7077e+09]])\n","tensor([0.])\n"]}],"source":["batch_iterator = iter(dataloader)\n","batch = next(batch_iterator)\n","input, output = batch\n","\n","\n","# Process the data and target tensors here\n","print(input)\n","print(output)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":515,"referenced_widgets":["d32ee38fe499466e91877e4d29a63b58","00a21c92b4204cf190c8111a6af5f921","08ae92ff3b244a04b052eadcc8a1b0f5","558f88797b874463aaa8f1d40615cc83","2c75bb9c3b94473d90bc3cf49e10b29c","cb2783e133884323b240c5bc15d27f3e","d1cb9cb395b2422aae2076b2e8633008","fbd7ee9bfdbf417b846af5842fcb0ffe","8f154a45ee034be191e7692f8cd0777a","b2efc1ecd7b24e93847f35e215993fac","57d13c10c18d474bbc1ba58d5021baba"]},"id":"Y8fcH9wAbDG4","outputId":"da7bea2a-a68c-451c-ce30-80f1cd54a54e","executionInfo":{"status":"ok","timestamp":1711918983175,"user_tz":240,"elapsed":49259,"user":{"displayName":"Aakarsh Rai","userId":"06387172182894839107"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO: \n","  | Name | Type | Params\n","------------------------------\n","0 | lstm | LSTM | 124   \n","------------------------------\n","124       Trainable params\n","0         Non-trainable params\n","124       Total params\n","0.000     Total estimated model params size (MB)\n","INFO:lightning.pytorch.callbacks.model_summary:\n","  | Name | Type | Params\n","------------------------------\n","0 | lstm | LSTM | 124   \n","------------------------------\n","124       Trainable params\n","0         Non-trainable params\n","124       Total params\n","0.000     Total estimated model params size (MB)\n"]},{"output_type":"display_data","data":{"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d32ee38fe499466e91877e4d29a63b58"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([375])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.l1_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([246])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.l1_loss(input, target, reduction=self.reduction)\n","INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n"]}],"source":["trainer.fit(first_lstm_model, train_dataloaders = dataloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ou4NEl0_dCcP"},"outputs":[],"source":["trainer.predict(first_lstm_model, inputs_tensor.unsqueeze(dim = 1))"]},{"cell_type":"code","source":["type(dataloader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":291},"id":"xjLXWYKVTSUC","executionInfo":{"status":"ok","timestamp":1711918631733,"user_tz":240,"elapsed":6,"user":{"displayName":"Aakarsh Rai","userId":"06387172182894839107"}},"outputId":"1ded2b3a-996f-4f45-94b5-011c34217d9d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.utils.data.dataloader.DataLoader"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>torch.utils.data.dataloader.DataLoader</b><br/>def __init__(dataset: Dataset[T_co], batch_size: Optional[int]=1, shuffle: Optional[bool]=None, sampler: Union[Sampler, Iterable, None]=None, batch_sampler: Union[Sampler[List], Iterable[List], None]=None, num_workers: int=0, collate_fn: Optional[_collate_fn_t]=None, pin_memory: bool=False, drop_last: bool=False, timeout: float=0, worker_init_fn: Optional[_worker_init_fn_t]=None, multiprocessing_context=None, generator=None, *, prefetch_factor: Optional[int]=None, persistent_workers: bool=False, pin_memory_device: str=&#x27;&#x27;)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py</a>Data loader. Combines a dataset and a sampler, and provides an iterable over\n","the given dataset.\n","\n","The :class:`~torch.utils.data.DataLoader` supports both map-style and\n","iterable-style datasets with single- or multi-process loading, customizing\n","loading order and optional automatic batching (collation) and memory pinning.\n","\n","See :py:mod:`torch.utils.data` documentation page for more details.\n","\n","Args:\n","    dataset (Dataset): dataset from which to load the data.\n","    batch_size (int, optional): how many samples per batch to load\n","        (default: ``1``).\n","    shuffle (bool, optional): set to ``True`` to have the data reshuffled\n","        at every epoch (default: ``False``).\n","    sampler (Sampler or Iterable, optional): defines the strategy to draw\n","        samples from the dataset. Can be any ``Iterable`` with ``__len__``\n","        implemented. If specified, :attr:`shuffle` must not be specified.\n","    batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n","        returns a batch of indices at a time. Mutually exclusive with\n","        :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n","        and :attr:`drop_last`.\n","    num_workers (int, optional): how many subprocesses to use for data\n","        loading. ``0`` means that the data will be loaded in the main process.\n","        (default: ``0``)\n","    collate_fn (Callable, optional): merges a list of samples to form a\n","        mini-batch of Tensor(s).  Used when using batched loading from a\n","        map-style dataset.\n","    pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n","        into device/CUDA pinned memory before returning them.  If your data elements\n","        are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n","        see the example below.\n","    drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n","        if the dataset size is not divisible by the batch size. If ``False`` and\n","        the size of dataset is not divisible by the batch size, then the last batch\n","        will be smaller. (default: ``False``)\n","    timeout (numeric, optional): if positive, the timeout value for collecting a batch\n","        from workers. Should always be non-negative. (default: ``0``)\n","    worker_init_fn (Callable, optional): If not ``None``, this will be called on each\n","        worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n","        input, after seeding and before data loading. (default: ``None``)\n","    multiprocessing_context (str or multiprocessing.context.BaseContext, optional): If\n","        ``None``, the default `multiprocessing context`_ of your operating system will\n","        be used. (default: ``None``)\n","    generator (torch.Generator, optional): If not ``None``, this RNG will be used\n","        by RandomSampler to generate random indexes and multiprocessing to generate\n","        ``base_seed`` for workers. (default: ``None``)\n","    prefetch_factor (int, optional, keyword-only arg): Number of batches loaded\n","        in advance by each worker. ``2`` means there will be a total of\n","        2 * num_workers batches prefetched across all workers. (default value depends\n","        on the set value for num_workers. If value of num_workers=0 default is ``None``.\n","        Otherwise, if value of ``num_workers &gt; 0`` default is ``2``).\n","    persistent_workers (bool, optional): If ``True``, the data loader will not shut down\n","        the worker processes after a dataset has been consumed once. This allows to\n","        maintain the workers `Dataset` instances alive. (default: ``False``)\n","    pin_memory_device (str, optional): the device to :attr:`pin_memory` to if ``pin_memory`` is\n","        ``True``.\n","\n","\n",".. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n","             cannot be an unpicklable object, e.g., a lambda function. See\n","             :ref:`multiprocessing-best-practices` on more details related\n","             to multiprocessing in PyTorch.\n","\n",".. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n","             When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n","             it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n","             rounding depending on :attr:`drop_last`, regardless of multi-process loading\n","             configurations. This represents the best guess PyTorch can make because PyTorch\n","             trusts user :attr:`dataset` code in correctly handling multi-process\n","             loading to avoid duplicate data.\n","\n","             However, if sharding results in multiple workers having incomplete last batches,\n","             this estimate can still be inaccurate, because (1) an otherwise complete batch can\n","             be broken into multiple ones and (2) more than one batch worth of samples can be\n","             dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n","             cases in general.\n","\n","             See `Dataset Types`_ for more details on these two types of datasets and how\n","             :class:`~torch.utils.data.IterableDataset` interacts with\n","             `Multi-process data loading`_.\n","\n",".. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and\n","             :ref:`data-loading-randomness` notes for random seed related questions.\n","\n",".. _multiprocessing context:\n","    https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 123);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"20hZPDEHhr7N"},"outputs":[],"source":["input = df.iloc[:, 0:19].values\n","input_tensor = torch.from_numpy(input)\n","labels = df.iloc[:, 19:20].values\n","labels_tensor = torch.from_numpy(labels)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1UTpEGiSQrwBGFpSFQimwKJf4QmJK7UNd","authorship_tag":"ABX9TyODMBNewll8pcL5ULe5QyO4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"d32ee38fe499466e91877e4d29a63b58":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_00a21c92b4204cf190c8111a6af5f921","IPY_MODEL_08ae92ff3b244a04b052eadcc8a1b0f5","IPY_MODEL_558f88797b874463aaa8f1d40615cc83"],"layout":"IPY_MODEL_2c75bb9c3b94473d90bc3cf49e10b29c"}},"00a21c92b4204cf190c8111a6af5f921":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb2783e133884323b240c5bc15d27f3e","placeholder":"​","style":"IPY_MODEL_d1cb9cb395b2422aae2076b2e8633008","value":"Epoch 9: 100%"}},"08ae92ff3b244a04b052eadcc8a1b0f5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbd7ee9bfdbf417b846af5842fcb0ffe","max":617,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8f154a45ee034be191e7692f8cd0777a","value":617}},"558f88797b874463aaa8f1d40615cc83":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2efc1ecd7b24e93847f35e215993fac","placeholder":"​","style":"IPY_MODEL_57d13c10c18d474bbc1ba58d5021baba","value":" 617/617 [00:04&lt;00:00, 145.35it/s, v_num=1]"}},"2c75bb9c3b94473d90bc3cf49e10b29c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"cb2783e133884323b240c5bc15d27f3e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1cb9cb395b2422aae2076b2e8633008":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fbd7ee9bfdbf417b846af5842fcb0ffe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f154a45ee034be191e7692f8cd0777a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b2efc1ecd7b24e93847f35e215993fac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57d13c10c18d474bbc1ba58d5021baba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}