# -*- coding: utf-8 -*-
"""FeatureMapAnalysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OS4cUJ15kZgHC7vnJ2K7hCSpPmqxCZil
"""

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
import pandas as pd
import numpy as np
import torchvision.datasets as datasets
import torchvision
import PIL
from PIL import Image
import matplotlib.pyplot as plt

if torch.cuda.is_available():
    device = "cuda"
else:
    device = "cpu"

train_dataset = torchvision.datasets.CIFAR10(
    root = "./",
    train = True,
    download = True,
    transform = torchvision.transforms.ToTensor()
)
test_dataset = torchvision.datasets.CIFAR10(
    root = "./",
    train = False,
    download = True,
    transform = torchvision.transforms.ToTensor()
)

train_dataloader = DataLoader(
    dataset = train_dataset,
    batch_size = 32,
    shuffle = True
)
test_dataloader = DataLoader(
    dataset = test_dataset,
    batch_size = 32,
    shuffle = True
)

class TinyVGG(nn.Module):
    def __init__(self, input_size):
        super().__init__()
        self.input_size = input_size
        self.block1 = []
        self.block2 = []
        self.conv_block_1 = nn.Sequential(
            nn.Conv2d(in_channels = input_size,
                      out_channels = 10,
                      stride = 1,
                      padding = 1,
                      kernel_size = 2),
            nn.ReLU(),
            nn.Conv2d(in_channels = 10,
                      out_channels = 20,
                      stride = 1,
                      padding = 1,
                      kernel_size = 2),
            nn.ReLU(),
            nn.MaxPool2d(2)

        )
        self.conv_block_2 = nn.Sequential(
            nn.Conv2d(in_channels = 20,
                      out_channels = 20,
                      stride = 1,
                      padding = 1,
                      kernel_size = 2),
            nn.ReLU(),
            nn.Conv2d(in_channels = 20,
                      out_channels = 20,
                      stride = 1,
                      padding = 1,
                      kernel_size = 2),
            nn.ReLU(),
            nn.MaxPool2d(2)
        )

        self.final_classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(in_features = 1620, out_features = 10)
        )

    def forward(self, batch):
        y_1 = self.conv_block_1(batch)
        self.block1.append(y_1)
        y_2 = self.conv_block_2(y_1)
        self.block2.append(y_2)
        logits = self.final_classifier(y_2)
        return logits, self.block1, self.block2

model = TinyVGG(3)
Loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)

# train_dataloader.to(device = device)
# test_dataloader.to(device = device)
model.to(device = device)

epoch = 5
for i in range(epoch):
    print(f"Epoch: {i+1}")
    epoch_loss = 0
    test_loss = 0
    train_correct = 0
    test_correct = 0
    for batch_idx, (x,y) in enumerate(train_dataloader):
        x = x.to(device = device)
        y = y.to(device = device)
        batch_loss = 0
        # print(x.shape)
        model.train()
        y_pred, block1, block2 = model(x)
        y_pred = nn.Softmax(dim = 1)(y_pred)
        loss = Loss_fn(y_pred, y)
        epoch_loss += loss.item()
        batch_loss = loss.item()
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        if (batch_idx + 1) % 50 == 0:
            print(f"batch loss: {batch_loss} for batch: {batch_idx+1}")
    print(f"epoch loss: {epoch_loss}")

import matplotlib.pyplot as plt
image = 0
label = 0
for images, labels in test_dataloader:
    image = images[0]
    label = labels[0]
    plt.imshow(image.numpy().transpose(1,2,0))
    break

import torchvision
torchvision.transforms.functional.to_pil_image(image)

a,b,c = model(image.unsqueeze(0).to(device = device))

b[-1].to(device = 'cpu').detach().squeeze(0)[i].unsqueeze(dim = 2).numpy().shape

i = 0

plt.imshow(b[-1].to(device = 'cpu').detach().squeeze(0)[i].unsqueeze(dim = 2).numpy(), cmap = 'gray')



image.unsqueeze(0).shape