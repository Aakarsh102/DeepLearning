{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP3Gc911SumRMs1Q1bBGPWQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"z7f-3RpQPBEC","executionInfo":{"status":"ok","timestamp":1715440461682,"user_tz":-330,"elapsed":17092,"user":{"displayName":"Aakarsh Rai","userId":"06387172182894839107"}}},"outputs":[],"source":["import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.datasets\n"]},{"cell_type":"code","source":["#devic agnostic code preperation\n","device = 'cpu'\n","if torch.cuda.is_available():\n","  device = 'cuda'"],"metadata":{"id":"NBcS5kTWVMKj","executionInfo":{"status":"ok","timestamp":1715440461682,"user_tz":-330,"elapsed":2,"user":{"displayName":"Aakarsh Rai","userId":"06387172182894839107"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["train_images = torchvision.datasets.FashionMNIST(\n","    root = \"data\",\n","    train = True,\n","    download = True,\n","    transform = torchvision.transforms.ToTensor(),\n","    target_transform = None\n",")\n","#train_images.to(\"cuda\")\n","test_images = torchvision.datasets.FashionMNIST(\n","    root = \"data\",\n","    train = False,\n","    download = True,\n","    transform = torchvision.transforms.ToTensor(),\n","    target_transform = None\n",")\n","#test_images.to(\"cuda\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5-qa4FjwPQo7","executionInfo":{"status":"ok","timestamp":1715440466607,"user_tz":-330,"elapsed":4927,"user":{"displayName":"Aakarsh Rai","userId":"06387172182894839107"}},"outputId":"b1aea251-d13c-42f2-9d38-db7cc963faf8"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 26421880/26421880 [00:01<00:00, 17515229.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 29515/29515 [00:00<00:00, 333141.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4422102/4422102 [00:00<00:00, 6081045.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5148/5148 [00:00<00:00, 4427368.67it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["image, lable = train_images[0]\n","image.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aA-P5PlXSiXZ","executionInfo":{"status":"ok","timestamp":1715429384022,"user_tz":-330,"elapsed":18,"user":{"displayName":"Aakarsh Rai","userId":"06387172182894839107"}},"outputId":"290a4801-acbd-41f2-f8cb-a0b2a76e052c"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 28, 28])"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["dataloader = torch.utils.data.DataLoader(dataset = train_images,\n","                             batch_size = 32,\n","                             shuffle = True,\n","                             )\n","test_dataloader = torch.utils.data.DataLoader(dataset = test_images,\n","                                              batch_size = 32,\n","                                              shuffle = True\n","                                              )"],"metadata":{"id":"XvPFpg-BS8xc","executionInfo":{"status":"ok","timestamp":1715440466607,"user_tz":-330,"elapsed":3,"user":{"displayName":"Aakarsh Rai","userId":"06387172182894839107"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["count = 0\n","for i,j in test_dataloader:\n","  print(i)\n","  print(\"##########\")\n","  print(j)\n","  if count == 4:\n","    break\n","  count += 1"],"metadata":{"id":"lwyufX8VKOHZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Image_Classification_Model(nn.Module):\n","    def __init__(self, input_size, output_size):\n","      super().__init__()\n","      self.layer_stack = nn.Sequential(\n","          nn.Flatten(),\n","          nn.Linear(in_features = input_size, out_features = input_size * 2),\n","          nn.ReLU(),\n","          nn.Linear(in_features = input_size * 2, out_features = output_size),\n","          nn.ReLU()\n","      )\n","\n","    def forward(self, input):\n","        return self.layer_stack(input)\n","\n"],"metadata":{"id":"UnxA-3_8gfSA","executionInfo":{"status":"ok","timestamp":1715440466607,"user_tz":-330,"elapsed":3,"user":{"displayName":"Aakarsh Rai","userId":"06387172182894839107"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["#creating the model\n","model = Image_Classification_Model(28**2, 10)\n","model.to(device)"],"metadata":{"id":"WMVwMaTtprR9","executionInfo":{"status":"ok","timestamp":1715440689514,"user_tz":-330,"elapsed":352,"user":{"displayName":"Aakarsh Rai","userId":"06387172182894839107"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f3748960-55ab-4257-8da8-334854af3184"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Image_Classification_Model(\n","  (layer_stack): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=784, out_features=1568, bias=True)\n","    (2): ReLU()\n","    (3): Linear(in_features=1568, out_features=10, bias=True)\n","    (4): ReLU()\n","  )\n",")"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["#Setting up loss fucntion and the optimizer\n","\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)"],"metadata":{"id":"J5XQTre3pdyv","executionInfo":{"status":"ok","timestamp":1715440692186,"user_tz":-330,"elapsed":541,"user":{"displayName":"Aakarsh Rai","userId":"06387172182894839107"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["model.state_dict()"],"metadata":{"id":"b6fA3FZUqEzh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def accuracy(y_true, y_pred):\n","    \"\"\"Calculates accuracy between truth labels and predictions.\n","\n","    Args:\n","        y_true (torch.Tensor): Truth labels for predictions.\n","        y_pred (torch.Tensor): Predictions to be compared to predictions.\n","\n","    Returns:\n","        [torch.float]: Accuracy value between y_true and y_pred, e.g. 78.45\n","    \"\"\"\n","    correct = torch.eq(y_true, y_pred).sum().item()\n","    acc = (correct / len(y_pred)) * 100\n","    return acc"],"metadata":{"id":"0XnJNJzpjhna","executionInfo":{"status":"ok","timestamp":1715431153363,"user_tz":-330,"elapsed":1,"user":{"displayName":"Aakarsh Rai","userId":"06387172182894839107"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["from tqdm.auto import tqdm\n"],"metadata":{"id":"yiGeKVeMpmV7","executionInfo":{"status":"ok","timestamp":1715429392669,"user_tz":-330,"elapsed":2,"user":{"displayName":"Aakarsh Rai","userId":"06387172182894839107"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["#Making the training loop\n","\n","epochs = 5\n","for i in range(epochs):\n","  total_loss = 0\n","  model.train()\n","  for batch, (x, y) in enumerate(dataloader):\n","    model.train()\n","    x = x.to(device)\n","    y = y.to(device)\n","\n","    y_pred = model(x)\n","\n","    loss = loss_fn(y_pred, y)\n","\n","    total_loss += loss\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if batch % (len(dataloader) - 1) == 0 and batch != 0:\n","      print(\"batch number %d in epoch %d......\" %(batch, i))\n","      #print(\"train loss --------- %f\" %(total_loss/len(dataloader)))\n","      print(\"train loss --------- %f\" %(loss))\n","\n","\n","    #testing section\n","      model.eval()\n","      with torch.inference_mode():\n","        total_test_loss = 0\n","        for x_test, y_test in test_dataloader:\n","          x_test = x_test.to(device)\n","          y_test = y_test.to(device)\n","          test_y_pred = model(x_test)\n","          test_y_probs = torch.softmax(test_y_pred, dim = 1)\n","          y_prediction = torch.argmax(test_y_probs, dim = 1)\n","          loss = loss_fn(test_y_pred, y_test)\n","          total_test_loss += loss\n","        print(\"test loss: --------- %f\" %(total_test_loss/len(dataloader)))\n","        print(\"test accuracy: ------ %f\" %(accuracy(y_test, y_prediction)))\n","\n","\n","\n",""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cj2d9R3fqrpq","executionInfo":{"status":"ok","timestamp":1715430830599,"user_tz":-330,"elapsed":49144,"user":{"displayName":"Aakarsh Rai","userId":"06387172182894839107"}},"outputId":"bf5b2442-a2ba-4e75-9c21-3c8c1fe8e1fc"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["batch number 1874 in epoch 0......\n","train loss --------- 0.628248\n","test loss: --------- 0.128117\n","test accuracy: ------ 75.000000\n","batch number 1874 in epoch 1......\n","train loss --------- 0.201165\n","test loss: --------- 0.073096\n","test accuracy: ------ 56.250000\n","batch number 1874 in epoch 2......\n","train loss --------- 0.173463\n","test loss: --------- 0.064385\n","test accuracy: ------ 100.000000\n","batch number 1874 in epoch 3......\n","train loss --------- 0.312550\n","test loss: --------- 0.060793\n","test accuracy: ------ 93.750000\n","batch number 1874 in epoch 4......\n","train loss --------- 0.649001\n","test loss: --------- 0.062259\n","test accuracy: ------ 100.000000\n"]}]},{"cell_type":"code","source":["def train_it(model, dataloader, loss_fn, optimizer, print_interval = 20, epochs = 100):\n","    #devic agnostic code preperation\n","    device = 'cpu'\n","    if torch.cuda.is_available():\n","        device = 'cuda'\n","\n","    def accuracy(y_true, y_pred):\n","        \"\"\"Calculates accuracy between truth labels and predictions.\n","\n","        Args:\n","            y_true (torch.Tensor): Truth labels for predictions.\n","            y_pred (torch.Tensor): Predictions to be compared to predictions.\n","\n","        Returns:\n","            [torch.float]: Accuracy value between y_true and y_pred, e.g. 78.45\n","        \"\"\"\n","        correct = torch.eq(y_true, y_pred).sum().item()\n","        acc = (correct / len(y_pred)) * 100\n","        return acc\n","\n","    #training loop\n","    for epoch in range(epochs):\n","        print(\"going through epoch: %d:\" % (epoch))\n","\n","        for batch_idx, (x_train, y_train) in enumerate(dataloader):\n","            model.train()\n","\n","            #setting up hardware\n","            model.to(device)\n","            x_train = x_train.to(device)\n","            y_train = y_train.to(device)\n","            # print(next(iter(k).device)\n","            # print(x_train.device)\n","            # print(y_train.device)\n","            #####\n","\n","            y_pred = model(x_train)\n","\n","            loss = loss_fn(y_pred, y_train)\n","            #total_loss += loss_fn\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            if batch_idx % print_interval == 0 and batch_idx != 0:\n","                print(\"  batch number ---------- %d....\" %(batch_idx))\n","                print(\"  batch train loss ------ %f....\" %(loss))\n","                y_probs = torch.softmax(y_pred, dim = 1)\n","                predictions = torch.argmax(y_probs, dim = 1)\n","                # print(predictions)\n","                print(\"  train accuracy -------- %f....\" %(accuracy(y_train,\n","                                                                    predictions\n","                                                                    )))\n","\n","\n","\n","# def test_it(model, dataloader):\n","\n","\n","\n","\n"],"metadata":{"id":"1I8Y0JUUdHNz","executionInfo":{"status":"ok","timestamp":1715440769375,"user_tz":-330,"elapsed":374,"user":{"displayName":"Aakarsh Rai","userId":"06387172182894839107"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["train_it(model, dataloader, loss_fn, optimizer, print_interval = 1874, epochs = 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mR5GI2_vjqIH","executionInfo":{"status":"ok","timestamp":1715440884980,"user_tz":-330,"elapsed":112354,"user":{"displayName":"Aakarsh Rai","userId":"06387172182894839107"}},"outputId":"1a71d214-229f-4d51-fd1b-b4ebbeb8c6ac"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["going through epoch: 0:\n","  batch number ---------- 1874....\n","  batch train loss ------ 0.841106....\n","  train accuracy -------- 71.875000....\n","going through epoch: 1:\n","  batch number ---------- 1874....\n","  batch train loss ------ 0.499399....\n","  train accuracy -------- 84.375000....\n","going through epoch: 2:\n","  batch number ---------- 1874....\n","  batch train loss ------ 0.568265....\n","  train accuracy -------- 78.125000....\n","going through epoch: 3:\n","  batch number ---------- 1874....\n","  batch train loss ------ 0.433304....\n","  train accuracy -------- 84.375000....\n","going through epoch: 4:\n","  batch number ---------- 1874....\n","  batch train loss ------ 0.420388....\n","  train accuracy -------- 81.250000....\n"]}]},{"cell_type":"code","source":["logits = model(testing_x)\n","prob = torch.softmax(logits, dim = 1)\n","preds = torch.argmax(prob, dim = 1)\n","print(preds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j77ehGX1layd","executionInfo":{"status":"ok","timestamp":1715440754986,"user_tz":-330,"elapsed":7,"user":{"displayName":"Aakarsh Rai","userId":"06387172182894839107"}},"outputId":"ebb239a4-baa1-4694-a528-444e78470c6f"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([3, 7, 1, 1, 9, 3, 3, 9, 1, 3, 1, 1, 3, 3, 4, 1, 1, 7, 1, 3, 1, 3, 1, 3,\n","        3, 1, 7, 4, 3, 3, 7, 7])\n"]}]},{"cell_type":"code","source":["testing_y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oZiwhqVdODam","executionInfo":{"status":"ok","timestamp":1715440576441,"user_tz":-330,"elapsed":3,"user":{"displayName":"Aakarsh Rai","userId":"06387172182894839107"}},"outputId":"c67cce77-b1fc-4c12-8e06-f3bae4b7cb6f"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([9, 4, 6, 4, 5, 4, 7, 8, 6, 2, 0, 4, 0, 4, 9, 3, 2, 5, 2, 2, 2, 6, 0, 4,\n","        3, 1, 5, 0, 0, 3, 9, 9])"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["new_logits = model(testing_x)\n","new_prob = torch.softmax(new_logits, dim = 1)\n","new_preds = torch.argmax(new_prob, dim = 1)\n","print(new_preds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l2W4hRZWPPry","executionInfo":{"status":"ok","timestamp":1715440895015,"user_tz":-330,"elapsed":372,"user":{"displayName":"Aakarsh Rai","userId":"06387172182894839107"}},"outputId":"2e45babe-21e1-48bd-ac03-61a3bda7b6fa"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([9, 4, 6, 4, 5, 4, 7, 8, 0, 4, 0, 4, 0, 4, 9, 3, 2, 5, 2, 6, 2, 6, 0, 4,\n","        3, 1, 5, 0, 6, 3, 9, 9])\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"rsVz6V3kPMQq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["testing_x = 0\n","testing_y = 0\n","for batch, (x,y) in enumerate(test_dataloader):\n","    testing_x = x\n","    testing_y = y\n","    break\n"],"metadata":{"id":"nIqT1iYdNvTV","executionInfo":{"status":"ok","timestamp":1715440546826,"user_tz":-330,"elapsed":1,"user":{"displayName":"Aakarsh Rai","userId":"06387172182894839107"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["from tqdm.auto import tqdm\n","\n","class PytorchModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def train_it(self, dataloader, loss_fn, epochs = 100):\n","        total_loss = 0\n","        for epoch in tqdm(range(epochs)):\n","            for batch_idx, (x_train, y_train) in enumerate(dataloader):\n","                #shifting to training mode\n","                self.train()\n","\n","                # going through the forward method\n","                y_logits = self.forward(x_train)\n","                y_probs = torch.softmax(y_logits, dim = 1)\n","                y_result = torch.argmax(y_probs, dim = 1)\n"],"metadata":{"id":"cMSvxDCDdlDc","executionInfo":{"status":"aborted","timestamp":1715429424481,"user_tz":-330,"elapsed":4,"user":{"displayName":"Aakarsh Rai","userId":"06387172182894839107"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["type(train_images)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"spayUVdtoliw","executionInfo":{"status":"ok","timestamp":1715430650418,"user_tz":-330,"elapsed":8,"user":{"displayName":"Aakarsh Rai","userId":"06387172182894839107"}},"outputId":"c6a7662c-0931-44b8-db09-a1ec23528e46"},"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torchvision.datasets.mnist.FashionMNIST"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>torchvision.datasets.mnist.FashionMNIST</b><br/>def __init__(root: str, train: bool=True, transform: Optional[Callable]=None, target_transform: Optional[Callable]=None, download: bool=False) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py</a>`Fashion-MNIST &lt;https://github.com/zalandoresearch/fashion-mnist&gt;`_ Dataset.\n","\n","Args:\n","    root (string): Root directory of dataset where ``FashionMNIST/raw/train-images-idx3-ubyte``\n","        and  ``FashionMNIST/raw/t10k-images-idx3-ubyte`` exist.\n","    train (bool, optional): If True, creates dataset from ``train-images-idx3-ubyte``,\n","        otherwise from ``t10k-images-idx3-ubyte``.\n","    download (bool, optional): If True, downloads the dataset from the internet and\n","        puts it in root directory. If dataset is already downloaded, it is not\n","        downloaded again.\n","    transform (callable, optional): A function/transform that  takes in an PIL image\n","        and returns a transformed version. E.g, ``transforms.RandomCrop``\n","    target_transform (callable, optional): A function/transform that takes in the\n","        target and transforms it.</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 202);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":47}]}]}