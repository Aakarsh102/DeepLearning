# -*- coding: utf-8 -*-
"""new_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xJgrsAcrdLZXDWrqwTMx1GllORSnevll
"""

import torch
import torch.nn as nn
import numpy as np
import pandas as pd
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader

data = np.load('/content/drive/MyDrive/geoml/mnist_test_seq.npy')
print(type(data))

print(data.shape)

data = data.transpose(1, 0, 2, 3)

first_image_sequence = data[0]  # Shape: (seq_len, width, height)

# Plot the sequence of 20 frames
plt.figure(figsize=(12, 6))
for i in range(20):
    plt.subplot(2, 10, i + 1)  # Arrange in a 2x10 grid
    plt.imshow(first_image_sequence[i], cmap="gray")
    plt.axis("off")
plt.suptitle("20 Frames of First Image Moving Sequence")
plt.show()

x = data[:, :10, :, :]    # First 10 frames
y = data[:, 10:20, :, :]  # Next 10 frames

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)

x_train_torch = torch.from_numpy(x_train).float()
y_train_torch = torch.from_numpy(y_train).float()
x_test_torch = torch.from_numpy(x_test).float()
y_test_torch = torch.from_numpy(y_test).float()

train_dataset = torch.utils.data.TensorDataset(x_train_torch, y_train_torch)
test_dataset = torch.utils.data.TensorDataset(x_test_torch, y_test_torch)

train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = 32, shuffle = True)
test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = 32, shuffle = True)

seq_length = 10
batch_size = 32
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
kernel_size = 3
kernel_size_for_conv = 5
stride = kernel_size_for_conv//2
num_layers = 2

#stuff to modify
seq_length;

# Bro please remember the out_channels and output sequence length stuff.

class modelthing(nn.Module):

    def __init__(self, in_channels, out_channels, frame_size,
        num_kernels=64, kernel_size=(3, 3), padding=(1, 1),
        num_layers=2, activation='tanh', device='cpu'):

        super(modelthing, self).__init__()
        self.num_conv_layers = 2
        self.frame_size = frame_size
        self.kernel_size_for_conv = 5
        print(self.frame_size)
        self.stride = 2
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.kernel_size = kernel_size
        self.padding = 2
        seq_length = 10
        self.hidden_state_layers = 8

        self.final_frame_size = self.frame_size_calc()
        self.num_layers = num_layers
        self.hidden_state_layers = 8
        print(self.final_frame_size)

        self.compression_layer = nn.Sequential(
            nn.Conv3d(
                in_channels = self.in_channels,
                out_channels = 1,
                kernel_size = (1, 1, 1))
        )


        self.encoder_section = nn.Sequential(
            nn.Conv2d(
            in_channels = seq_length,
            out_channels = seq_length,
            kernel_size = self.kernel_size_for_conv,
            padding = self.padding,
            stride = self.stride
            ),
            nn.ReLU(),
            nn.Conv2d(
                in_channels = seq_length,
                out_channels = seq_length,
                kernel_size = self.kernel_size_for_conv,
                padding = self.padding,
                stride = self.stride
            ),
            nn.ReLU()
        )
        self.time_section = nn.Sequential(
        ConvLSTM(
            in_channels=1,
            out_channels=self.hidden_state_layers,
            kernel_size= self.kernel_size,
            padding=(self.padding, self.padding),
            activation = 'tanh',
            device = device,
            frame_size = self.final_frame_size
        ),
        nn.BatchNorm3d(num_features = self.hidden_state_layers),
        ConvLSTM(
            in_channels = self.hidden_state_layers,
            out_channels = self.hidden_state_layers,
            kernel_size = self.kernel_size,
            padding = (self.padding, self.padding),
            activation = 'tanh',
            device = device,
            frame_size = self.final_frame_size
        )

        )

        self.decoder_section = nn.Sequential (
            nn.ConvTranspose2d(
                in_channels = self.hidden_state_layers,
                out_channels = abs(self.hidden_state_layers - self.out_channels)//2,
                kernel_size = kernel_size_for_conv,
                padding = self.padding,
                output_padding = 1,
                stride = self.stride
            ),
            nn.ReLU(),
            nn.ConvTranspose2d(
                in_channels = abs(self.hidden_state_layers - self.out_channels)//2,
                out_channels = self.out_channels,
                kernel_size = kernel_size_for_conv,
                padding = self.padding,
                output_padding = 1,
                stride = self.stride
            )
        )


    def frame_size_calc(self):
        h = self.frame_size[0]
        w = self.frame_size[1]

        for i in range(self.num_conv_layers):
            # Combine the operations in the correct order
            w = ((w + 2*self.padding - self.kernel_size_for_conv) // self.stride) + 1
            h = ((h + 2*self.padding - self.kernel_size_for_conv) // self.stride) + 1

        return (h, w)




    def forward(self, x):
        # x = self.encoder_section(x)
        # x = x.unsqueeze(dim = 1)
        # print(self.frame_size_calc())
        # print("this")
        # print(x.shape)
        # x = self.time_section(x)

        # x = x[:, :, -1, :, :]
        # x = x.squeeze(dim = 2)
        # x = self.decoder_section(x)
        # print(x.shape)
        # return x


        # # Decode
        # x = self.decoder_section(x)

        print("Initial input:", x.shape)
        x = self.compression_layer(x)
        print("After compression:", x.shape)
        x = x.squeeze(dim = 1)
        print("After compression:", x.shape)
        x = self.encoder_section(x)
        print("After encoder:", x.shape)
        x = x.unsqueeze(dim = 1)
        print("After unsqueeze:", x.shape)

        x = self.time_section(x)
        print("After time section:", x.shape)
        x = x[:, :, -1, :, :]
        x = x.squeeze(dim = 2)
        print("Before decoder:", x.shape)
        x = self.decoder_section(x)
        print("Final output:", x.shape)
        return x

model = modelthing(in_channels = 1, out_channels=10, frame_size = (64,64))
model  = model.to(device)
loss_fn = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)

model.train()

epochs = 20
for i in range(epochs):
    for batch_idx, (x, y) in enumerate(train_dataloader):
        x = x.to(device)
        y = y.to(device)
        x = x.unsqueeze(dim = 1)

        print("Training input shape:", x.shape)\


        output = model(x)
        loss = loss_fn(output, y)
        print(f"Epoch:{0} :::: Batch:{1} :::: Loss:{2}".format(i, batch_idx, loss))
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

h, w = 64, 64
val =  1
for i in range(2):
    w = w + val
    h = h + val
    w = w//(2) + 1
    h = h//2 + 1

h, w = 16, 16

h = 64
w = 64
val = 2 * 2 - 5
for i in range(2):
    w = w - val
    h = h - val
    w = w//(2) + 1
    h = h//2 + 1









class ConvLSTMCell(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, frame_size, activation='tanh'):
        super(ConvLSTMCell, self).__init__()

        if activation == "tanh":
            self.activation = torch.tanh
        elif activation == "relu":
            self.activation = torch.relu

        # Idea adapted from https://github.com/ndrplz/ConvLSTM_pytorch
        self.conv = nn.Conv2d(
            in_channels=in_channels + out_channels,
            out_channels=4 * out_channels,
            kernel_size=kernel_size,
            padding=padding)

        # Initialize weights for Hadamard Products with the correct size
        # Note: frame_size should be the size after encoding (16, 16)
        self.W_ci = nn.Parameter(torch.Tensor(out_channels, *frame_size))
        self.W_co = nn.Parameter(torch.Tensor(out_channels, *frame_size))
        self.W_cf = nn.Parameter(torch.Tensor(out_channels, *frame_size))

        # Initialize parameters
        for param in [self.W_ci, self.W_co, self.W_cf]:
            nn.init.xavier_uniform_(param)

    def forward(self, X, H_prev, C_prev):
        # Debug prints
        # print("X shape:", X.shape)
        # print("H_prev shape:", H_prev.shape)
        # print("C_prev shape:", C_prev.shape)
        # print("W_ci shape:", self.W_ci.shape)

        # Concatenate input and previous hidden state
        conv_output = self.conv(torch.cat([X, H_prev], dim=1))

        # Split the combined output into the gates
        i_conv, f_conv, C_conv, o_conv = torch.chunk(conv_output, chunks=4, dim=1)

        # Ensure broadcasting works correctly
        W_ci = self.W_ci.unsqueeze(0).expand(X.size(0), -1, -1, -1)
        W_cf = self.W_cf.unsqueeze(0).expand(X.size(0), -1, -1, -1)
        W_co = self.W_co.unsqueeze(0).expand(X.size(0), -1, -1, -1)

        input_gate = torch.sigmoid(i_conv + W_ci * C_prev)
        forget_gate = torch.sigmoid(f_conv + W_cf * C_prev)

        # Current Cell output
        C = forget_gate * C_prev + input_gate * self.activation(C_conv)

        output_gate = torch.sigmoid(o_conv + W_co * C)

        # Current Hidden State
        H = output_gate * self.activation(C)

        return H, C


class ConvLSTM(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, frame_size,
                 activation='tanh', device='cuda'):
        super(ConvLSTM, self).__init__()

        self.device = device
        self.out_channels = out_channels

        # We will unroll this over time steps
        self.convLSTMcell = ConvLSTMCell(
            in_channels, out_channels,
            kernel_size, padding, frame_size, activation
        )

    def forward(self, X):
        # X is a frame sequence (batch_size, num_channels, seq_len, height, width)
        batch_size, _, seq_len, height, width = X.size()

        # Initialize output
        output = torch.zeros(batch_size, self.out_channels, seq_len,
                           height, width, device=self.device)

        # Initialize Hidden State
        H = torch.zeros(batch_size, self.out_channels,
                       height, width, device=self.device)

        # Initialize Cell Input
        C = torch.zeros(batch_size, self.out_channels,
                       height, width, device=self.device)

        # Unroll over time steps
        for time_step in range(seq_len):
            H, C = self.convLSTMcell(X[:, :, time_step], H, C)
            output[:, :, time_step] = H

        return output

# Original ConvLSTM cell as proposed by Shi et al.
class ConvLSTMCell(nn.Module):


    def __init__(self, in_channels, out_channels,
        kernel_size, padding, frame_size, activation='tanh'):

        super(ConvLSTMCell, self).__init__()

        if activation == "tanh":
            self.activation = torch.tanh
        elif activation == "relu":
            self.activation = torch.relu

        # Idea adapted from https://github.com/ndrplz/ConvLSTM_pytorch
        self.conv = nn.Conv2d(
            in_channels=in_channels + out_channels,
            out_channels=4 * out_channels,
            kernel_size=kernel_size,
            padding=padding)

        # Initialize weights for Hadamard Products
        self.W_ci = nn.Parameter(torch.Tensor(out_channels, *frame_size))
        self.W_co = nn.Parameter(torch.Tensor(out_channels, *frame_size))
        self.W_cf = nn.Parameter(torch.Tensor(out_channels, *frame_size))


    def forward(self, X, H_prev, C_prev):

        # Idea adapted from https://github.com/ndrplz/ConvLSTM_pytorch
        conv_output = self.conv(torch.cat([X, H_prev], dim=1))

        # Idea adapted from https://github.com/ndrplz/ConvLSTM_pytorch
        i_conv, f_conv, C_conv, o_conv = torch.chunk(conv_output, chunks=4, dim=1)

        input_gate = torch.sigmoid(i_conv + self.W_ci * C_prev )
        forget_gate = torch.sigmoid(f_conv + self.W_cf * C_prev )

        # Current Cell output
        C = forget_gate*C_prev + input_gate * self.activation(C_conv)

        output_gate = torch.sigmoid(o_conv + self.W_co * C )

        # Current Hidden State
        H = output_gate * self.activation(C)

        return H, C


class ConvLSTM(nn.Module):

    def __init__(self, in_channels, out_channels,
        kernel_size, padding, frame_size,
        activation='tanh', C = False, device=device):

        super(ConvLSTM, self).__init__()

        self.device = device

        self.out_channels = out_channels

        # We will unroll this over time steps
        self.convLSTMcell = ConvLSTMCell(
            in_channels, out_channels,
            kernel_size, padding, frame_size, activation
        )


    def forward(self, X):

        # X is a frame sequence (batch_size, num_channels, seq_len, height, width)

        # Get the dimensions
        batch_size, _, seq_len, height, width = X.size()

        # Initialize output
        output = torch.zeros(batch_size, self.out_channels, seq_len,
        height, width, device=self.device)

        # Initialize Hidden State
        H = torch.zeros(batch_size, self.out_channels,
        height, width, device=self.device)

        # Initialize Cell Input
        # if (C == False):
        #     C = torch.zeros(batch_size,self.out_channels,
        #     height, width, device=self.device)
        # else:
        #     C = C
        C = torch.zeros(batch_size,self.out_channels,
            height, width, device=self.device)

        # Unroll over time steps
        for time_step in range(seq_len):

            H, C = self.convLSTMcell(X[:,:,time_step], H, C)

            output[:,:,time_step] = H

        return output

class ConvLSTM_statefull_layer(nn.Module):

    def __init__(self, in_channels, out_channels,
        kernel_size, padding, frame_size,
        activation='tanh', C = False, device=device):

        super(ConvLSTM_decthing, self).__init__()

        self.device = device

        self.out_channels = out_channels

        # We will unroll this over time steps
        self.convLSTMcell = ConvLSTMCell(
            in_channels, out_channels,
            kernel_size, padding, frame_size, activation
        )


    def forward(self, X, C):

        # X is a frame sequence (batch_size, num_channels, seq_len, height, width)

        # Get the dimensions
        batch_size, _, seq_len, height, width = X.size()

        # Initialize output
        output = torch.zeros(batch_size, self.out_channels, seq_len,
        height, width, device=self.device)

        # Initialize Hidden State
        H = torch.zeros(batch_size, self.out_channels,
        height, width, device=self.device)

        # Initialize Cell Input
        # if (C == False):
        #     C = torch.zeros(batch_size,self.out_channels,
        #     height, width, device=self.device)
        # else:
        #     C = C

        # Unroll over time steps
        for time_step in range(seq_len):

            H, C = self.convLSTMcell(X[:,:,time_step], H, C)

            output[:,:,time_step] = H

        return output
